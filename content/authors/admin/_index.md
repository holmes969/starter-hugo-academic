---
title: Cheng Zhang
role: Research scientist Meta Reality Labs
avatar_filename: profile_2.jpeg
bio: My research interests include distributed robotics, mobile computing and
  programmable matter.
interests:
  - Computer Graphics
  - Computer Vision
social:
  - icon: envelope
    icon_pack: fas
    link: /#contact
  - icon: twitter
    icon_pack: fab
    link: https://twitter.com/GeorgeCushen
  - icon: graduation-cap
    icon_pack: fas
    link: https://scholar.google.co.uk/citations?user=sIwtMXoAAAAJ
  - icon: github
    icon_pack: fab
    link: https://github.com/gcushen
  - icon: linkedin
    icon_pack: fab
    link: https://www.linkedin.com/
organizations:
  - name: Stanford University
    url: https://www.stanford.edu/
education:
  courses:
    - course: PhD in Artificial Intelligence
      institution: Stanford University
      year: 2012
    - course: MEng in Artificial Intelligence
      institution: Massachusetts Institute of Technology
      year: 2009
    - course: BSc in Artificial Intelligence
      institution: Massachusetts Institute of Technology
      year: 2008
email: ""
superuser: true
highlight_name: true
---
I am a research scientist at [Meta (formally known as Facebook) Reality Labs](https://about.facebook.com/realitylabs/). I received my Ph.D. degree from the University of California Irvine in 2022, advised by Prof. [Shuang Zhao](https://shuangz.com/). During my Ph.D. studies, I was awarded the [2021 Facebook Fellowship](https://research.fb.com/fellows/zhang-cheng//). Before that, I obtained my B.E. in Electrical Engineering from BJUT (2011-2015) and my M.S. in Computer Science from Columbia University (2015-2017).

My research focuses on physics-based rendering and its inverse problems (i.e., analysis by synthesis) centered around the inference of geometric and material properties from physical measurements (e.g., photographs, depth data). To develop a general solution to various inverse rendering problems, I have been working actively on the topic of physics-based differentiable rendering.